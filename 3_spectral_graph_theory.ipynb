{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 3: spectral graph theory\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Michaël Defferrard](http://deff.ch), [EPFL LTS2](https://lts2.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `8`\n",
    "* Students: `Matyas Lustig, Aurélien Pomini, David Salathé, Justine Weber`\n",
    "* Dataset: `Flight Routes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this milestone is to get familiar with the graph Laplacian and its spectral decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `No module named 'sklearn'` error when running the below cell, install [scikit-learn](https://scikit-learn.org) with `conda install scikit-learn` (after activating the `ntds_2018` environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote your graph as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E}, A)$, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, $A \\in \\mathbb{R}^{N \\times N}$ is the (weighted) adjacency matrix, and $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Import the adjacency matrix $A$ that you constructed in the first milestone.\n",
    "(You're allowed to update it between milestones if you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ALL Should we use the weighted one?\n",
    "adjacency_uw =  np.load('data/adjacency_sym_mtx_uw.npy')  # the unweighted adjacency matrix\n",
    "adjacency =  np.load('data/adjacency_sym_mtx.npy')  # the weighted adjacency matrix\n",
    "n_nodes =  adjacency_uw.shape[0] # the number of nodes in the network\n",
    "adjacency_uw[np.diag_indices_from(adjacency_uw)] = 0 # set diagonal elements to 0 (see comment)\n",
    "adjacency[np.diag_indices_from(adjacency)] = 0 # set diagonal elements to 0 (see comment)\n",
    "n_edges =  adjacency_uw.sum() / 2 # the number of edges in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "From the (weighted) adjacency matrix $A$, compute both the combinatorial (also called unnormalized) and the normalized graph Laplacian matrices.\n",
    "\n",
    "Note: if your graph is weighted, use the weighted adjacency matrix. If not, use the binary adjacency matrix.\n",
    "\n",
    "For efficient storage and computation, store these sparse matrices in a [compressed sparse row (CSR) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_combinatorial =  sparse.csgraph.laplacian(adjacency, normed=False).astype('float64')\n",
    "laplacian_normalized =  sparse.csgraph.laplacian(adjacency, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of them as the graph Laplacian $L$ for the rest of the milestone.\n",
    "We however encourage you to run the code with both to get a sense of the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = laplacian_combinatorial\n",
    "#laplacian = laplacian_normalized\n",
    "\n",
    "# Either laplacian_combinatorial or laplacian_normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the eigendecomposition of the Laplacian $L = U^\\top \\Lambda U$, where the columns $u_k \\in \\mathbb{R}^N$ of $U = [u_1, \\dots, u_N] \\in \\mathbb{R}^{N \\times N}$ are the eigenvectors and the diagonal elements $\\lambda_k = \\Lambda_{kk}$ are the corresponding eigenvalues.\n",
    "\n",
    "Make sure that the eigenvalues are ordered, i.e., $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.95221766e-15 7.95221766e-15 7.95221766e-15 ... 2.40222827e+02\n",
      " 2.43239875e+02 2.47215876e+02]\n"
     ]
    }
   ],
   "source": [
    "# it is not possible to compute all eigenvalues with sparse.linalg.eigs\n",
    "#eigenvalues, eigenvectors = sparse.linalg.eigs(laplacian, k = n_nodes-2)\n",
    "\n",
    "eigenvalues, eigenvectors = scipy.linalg.eigh(laplacian)\n",
    "\n",
    "print(eigenvalues)\n",
    "eigenvectors.shape\n",
    "#eigenvectors =  # Your code here.\n",
    "#eigenvalues =  # Your code here.\n",
    "\n",
    "assert eigenvectors.shape == (n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE almost equal : 13\n"
     ]
    }
   ],
   "source": [
    "idx = 13\n",
    "u = eigenvectors[:, idx]\n",
    "c = laplacian.dot(u)\n",
    "\n",
    "for i in range(3179) :\n",
    "    a = eigenvalues[i] * u\n",
    "    if (np.allclose(a,c, 0.000000000000000000000000000000000000000001)) :\n",
    "        print('TRUE almost equal :', i)    \n",
    "    if (np.array_equal(a,c)) :\n",
    "        print('TRUE equal :', i)\n",
    "    #else :\n",
    "       # print('FALSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your choice of eigensolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We will use the fact that our matrix is symmetric and use the scipy.linalg.eigh() function which is designed for this situation.\n",
    "\n",
    "sparse.linalg.eigs() provides a fast way to get the first k << N eigenvalues of a sparse matrix, using a partial decomposition. However it is not possible to compute all eigenvalues with sparse.linalg.eigs().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We can write $L = S S^\\top$. What is the matrix $S$? What does $S^\\top x$, with $x \\in \\mathbb{R}^N$, compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix $S$ is the incidence matrix whose elements are equal to $0$ or $\\pm 1$. The rows are for nodes and columns for edges. $S(i,j)$ is equal to $+1$ if there is an edge $e_j = (v_i, v_k)$ and equal to $-1$ if there is an edge $e_j = (v_k, v_i)$ for some node $k$, the $0$ is the for other cases.\n",
    "\n",
    "If there is a signal $x \\in \\mathbb{R}^N$ then $S^\\top x$ computes the gradient of $x$. It is a generalization of the fact that $(S^\\top x)[j] = x[i] - x[k]$ is a derivative of $x$ along edge $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show that $\\lambda_k = \\| S^\\top u_k \\|_2^2$, where $\\| \\cdot \\|_2^2$ denotes the squared Euclidean norm (a.k.a. squared $L^2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\| S^\\top u_k \\|_2^2 =  u_k^\\top S S^\\top u_k = u_k^\\top L u_k$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; and while $u_k = D^{-1/2}f_k$ where $D$ is a diagonal degree matrix we can write\n",
    "\n",
    "$=(D^{-1/2}f_k)^\\top L D^{-1/2}f_k$\n",
    "\n",
    "$=f_k^\\top (D^{-1/2})^\\top L D^{-1/2}f_k$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; as $D$ is diagonal we know that $D=D^\\top$ and $L_{norm} = D^{-1/2} L D^{-1/2}$ we can deduce\n",
    "\n",
    "$=f^\\top L_{norm} f_k$\n",
    "\n",
    "$=\\lambda_k$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the desired eigenvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the quantity $\\| S^\\top x \\|_2^2$ tell us about $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a quadratic Dirichlet form, a measure of how smooth a signal $x$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the value of $u_0$, both for the combinatorial and normalized Laplacians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00072696 0.00072696 0.00072696 ... 0.00072696 0.00072696 0.00072696]\n",
      "0.45504435340037247\n",
      "[-0.00122639 -0.00162236 -0.00183958 ... -0.00086719 -0.00061319\n",
      " -0.00061319]\n",
      "0.6025124820458465\n"
     ]
    }
   ],
   "source": [
    "# NOT SURE\n",
    "eigenvalues_comb, eigenvectors_comb = scipy.linalg.eigh(laplacian_combinatorial)\n",
    "eigenvalues_norm, eigenvectors_norm = scipy.linalg.eigh(laplacian_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinatorial u0 : \n",
      " [0.00072696 0.00072696 0.00072696 ... 0.00072696 0.00072696 0.00072696]\n",
      "min (absolute) value :  0.0007269553123246834\n",
      "max (absolute) value :  0.45504435340037247\n",
      "\n",
      "Normalized u0 \n",
      " [-0.00122639 -0.00162236 -0.00183958 ... -0.00086719 -0.00061319\n",
      " -0.00061319]\n",
      "min (absolute) value :  0.0006131927681965665\n",
      "max (absolute) value :  0.6025124820458465\n"
     ]
    }
   ],
   "source": [
    "u0_comb = eigenvectors_comb[:,0]\n",
    "u0_norm = eigenvectors_norm[:,0]\n",
    "print(\"Combinatorial u0 : \\n\", u0_comb)\n",
    "print(\"min (absolute) value : \", np.min(np.absolute(u0_comb)))\n",
    "print(\"max (absolute) value : \", np.max(np.absolute(u0_comb)))\n",
    "print(\"\\nNormalized u0 \\n\", u0_norm)\n",
    "print(\"min (absolute) value : \", np.min(np.absolute(u0_norm)))\n",
    "print(\"max (absolute) value : \", np.max(np.absolute(u0_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Look at the spectrum of the Laplacian by plotting the eigenvalues.\n",
    "Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1144d68dd8>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "We can see that the eigenvalues' values are rising exponentially, an abrupt increase takes place around the last fifth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components are there in your graph? Answer using the eigenvalues only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = eigenvalues[0]\n",
    "\n",
    "n_components = np.count_nonzero(eigenvalues == min_value)\n",
    "n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an upper bound on the eigenvalues, i.e., what is the largest possible eigenvalue? Answer for both the combinatorial and normalized Laplacians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247.2158761015632\n",
      "2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "print(max(eigenvalues_comb))\n",
    "print(max(eigenvalues_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "An upper bound exists for the normalized Laplacian eigenvalues and is equal to 2 if and only if we are dealing with a bipartite graph which we can observe in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Laplacian eigenmaps\n",
    "\n",
    "*Laplacian eigenmaps* is a method to embed a graph $\\mathcal{G}$ in a $d$-dimensional Euclidean space.\n",
    "That is, it associates a vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$.\n",
    "The graph $\\mathcal{G}$ is thus embedded as $Z \\in \\mathbb{R}^{N \\times d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What do we use Laplacian eigenmaps for? (Or more generally, graph embeddings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph embeddings map networks, graphs into a vector space preserving relevant network properties. Laplacian eigenmaps produce coordinate maps that are smooth functions over the original graph. That alows us to reduce the possible dimensions of each of the graph data point based on their similarity. Which is useful for making any computations less demanding and clearer visualization of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Embed your graph in $d=2$ dimensions with Laplacian eigenmaps.\n",
    "Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "\n",
    "**Recompute** the eigenvectors you need with a partial eigendecomposition method for sparse matrices.\n",
    "When $k \\ll N$ eigenvectors are needed, partial eigendecompositions are much more efficient than complete eigendecompositions.\n",
    "A partial eigendecomposition scales as $\\Omega(k |\\mathcal{E}|$), while a complete eigendecomposition costs $\\mathcal{O}(N^3)$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.86575066e-07  2.74909166e-07]\n",
      " [ 2.86579665e-07  2.74913302e-07]\n",
      " [ 2.86575163e-07  2.74909252e-07]\n",
      " ...\n",
      " [ 3.87281877e-11  2.23960552e-11]\n",
      " [ 2.70666528e-07 -9.72679744e-08]\n",
      " [ 2.23910893e-06  1.66091839e-06]]\n"
     ]
    }
   ],
   "source": [
    "# From assistant ??\n",
    "k_eig_val, k_eig_vect = scipy.sparse.linalg.eigsh(laplacian_combinatorial, k=3, which='LM') # which = largest eigen values -> change ?\n",
    "eigen_map = k_eig_vect[:,[1,2]]\n",
    "print(eigen_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the nodes embedded in 2D. Comment on what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the embedding $Z \\in \\mathbb{R}^{N \\times d}$ preserve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case $Z$ is the large data matrix, $N$ is the number of data points and $d$ the dimension of each of the data points which we want to reduce. The embeding preserves the relevant network properties, the number of nodes.\n",
    "\n",
    "**not sure..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Spectral clustering\n",
    "\n",
    "*Spectral clustering* is a method to partition a graph into distinct clusters.\n",
    "The method associates a feature vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$, then runs [$k$-means](https://en.wikipedia.org/wiki/K-means_clustering) in the embedding space $\\mathbb{R}^d$ to assign each node $v_i \\in \\mathcal{V}$ to a cluster $c_j \\in \\mathcal{C}$, where $k = |\\mathcal{C}|$ is the number of desired clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose $k$ and $d$. How did you get to those numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "1. Embed your graph in $\\mathbb{R}^d$ as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "   Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "1. If you want $k=2$ clusters, partition with the Fiedler vector. For $k > 2$ clusters, run $k$-means on $Z$. Don't implement $k$-means, use the `KMeans` class imported from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Use the computed cluster assignment to reorder the adjacency matrix $A$.\n",
    "What do you expect? What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "If you have ground truth clusters for your dataset, compare the cluster assignment from spectral clustering to the ground truth.\n",
    "A simple quantitative measure is to compute the percentage of nodes that have been correctly categorized.\n",
    "If you don't have a ground truth, qualitatively assess the quality of the clustering.\n",
    "\n",
    "Ground truth clusters are the \"real clusters\".\n",
    "For example, the genre of musical tracks in FMA, the category of Wikipedia articles, the spammer status of individuals, etc.\n",
    "Look for the `labels` in the [dataset descriptions](https://github.com/mdeff/ntds_2018/tree/master/projects/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Plot the cluster assignment (one color per cluster) on the 2D embedding you computed above with Laplacian eigenmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Why did we use the eigenvectors of the graph Laplacian as features? Could we use other features for clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
